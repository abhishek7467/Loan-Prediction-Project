# -*- coding: utf-8 -*-
"""Loan Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BeA1ylk_c4L5XkiauJA4SLnkeufzUZWR

# Loan Prediction Project

In finance, a loan is the lending of money by one or more individuals, organizations, or other entities to other individuals, organizations, etc. The recipient (i.e., the borrower) incurs a debt and is usually liable to pay interest on that debt until it is repaid as well as to repay the principal amount borrowed.
"""

# Data analysis and visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from math import pi
import seaborn as sns
import warnings# warning filter

# classifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# metrics
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score



from xgboost import XGBClassifier


#default theme
sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)

#warning hadle
warnings.filterwarnings("ignore")

loan_train = pd.read_csv('/content/train_loan.csv')
loan_test = pd.read_csv('/content/test_loan.csv')

# preview data

loan_train.head()

# preview of test data

loan_test.head()

# Copy the data, I will use the copy to create some visualization of categorical data using a loop
# This is a fix, because I dealt with the missing data earlier

loan_train_cc = loan_train.copy()

loan_train.columns

loan_test.columns

loan_train.dtypes

loan_train.describe()

len(loan_train)

len(loan_test)

# We have missing data
loan_train.isna().values.any()

# we have missing data
loan_test.isna().values.any()

loan_train.isnull().sum()

import seaborn as sns

plt.figure(figsize=(10,6))
sns.displot(
    data=loan_train.isna().melt(value_name="missing"),
    y="variable",
    hue="missing",
    multiple="fill",
    aspect=1.25)

plt.show()

loan_train.isna().sum()

# We'll do a forward fill here, so, we get only 1 or 0 to fill the missing data

loan_train['Credit_History'].fillna(method='ffill', inplace=True)
loan_train['Credit_History'].isna().values.any()

# We'll fill this column using the median of the values

median_loan = loan_train['Loan_Amount_Term'].median()
loan_train['Loan_Amount_Term'].fillna((median_loan), inplace=True)
loan_train['Loan_Amount_Term'].isna().values.any()

# We'll fill this column using the median of the values

median_loan_amount = loan_train['LoanAmount'].median()
loan_train['LoanAmount'].fillna((median_loan_amount), inplace=True)
loan_train['LoanAmount'].isna().values.any()

# Count the values to know which occurs most frequently
loan_train['Self_Employed'].value_counts()

#Fill with mode
loan_train['Self_Employed'].fillna('No', inplace=True)
loan_train['Self_Employed'].isna().values.any()

# fill with mode
loan_train['Dependents'].fillna(0, inplace=True)
loan_train['Dependents'].isna().values.any()

loan_train['Married'].mode()

# fill with mode
loan_train['Married'].fillna('Yes', inplace=True)
loan_train['Married'].isna().values.any()

loan_train['Gender'].mode()

# fill with mode
loan_train['Gender'].fillna('Male', inplace=True)
loan_train['Gender'].isna().values.any()

# Let's run a quick check
loan_train.isna().sum()

# A preview of missing data in the testing set

loan_test.isna().sum()

# fill in credit history
loan_test['Credit_History'].fillna(method='ffill', inplace=True)

# fill in loan amount term
median_loan_test = loan_test['Loan_Amount_Term'].median()
loan_test['Loan_Amount_Term'].fillna((median_loan_test), inplace=True)

# fill in loan amount
median_loan_amount_test = loan_test['LoanAmount'].median()
loan_test['LoanAmount'].fillna((median_loan_amount_test), inplace=True)

# fill in self employed
loan_test['Self_Employed'].fillna('No', inplace=True)

# fill in dependents
loan_test['Dependents'].fillna(0, inplace=True)

# fill in gender
loan_test['Gender'].fillna('Male', inplace=True)

loan_test.isna().values.any()

# Let's run a final check

loan_test.isna().sum()

"""Let's deal with duplicate values"""

loan_train.duplicated().values.any()

loan_test.duplicated().values.any()

"""Data Visualization & Exploratory Analysis"""

# Let's preview the data again

loan_train.head()

# Bar charts to get a high level view of categorical data

fig, ax = plt.subplots(3, 2, figsize=(16, 18))

loan_train.groupby(['Gender'])[['Gender']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))), ax=ax[0,0])
loan_train.groupby(['Married'])[['Married']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))), ax=ax[0,1])
loan_train.groupby(['Education'])[['Education']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))), ax=ax[1,0])
loan_train.groupby(['Self_Employed'])[['Self_Employed']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))), ax=ax[1,1])

loan_train.groupby(['Loan_Status'])[['Loan_Status']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))),ax=ax[2,0])
loan_train.groupby(['Property_Area'])[['Loan_Status']].count().plot.bar(
    color=plt.cm.Paired(np.arange(len(loan_train))),ax=ax[2,1])

plt.show()

# Here, I pass all categorical columns into a list

categorical_columns = loan_train_cc.select_dtypes('object').columns.to_list()

# This code loops through the list, and creates a chart for each

for i in categorical_columns[1:]: 
    plt.figure(figsize=(15,10))
    plt.subplot(3,2,1)
    sns.countplot(x=i ,hue='Loan_Status', data=loan_train_cc, palette='ocean')
    plt.xlabel(i, fontsize=14)

#Plot4- Scatterplot
fig, ax = plt.subplots(2,2, figsize=(14,12))

sns.scatterplot(data=loan_train,x="ApplicantIncome", y="LoanAmount",s=70, hue="Loan_Status", palette='ocean',ax=ax[0,0])
sns.histplot(loan_train, x=loan_train['LoanAmount'], bins=10, ax=ax[0,1])
sns.scatterplot(data=loan_train,x='CoapplicantIncome', y='LoanAmount',s=70, hue='Loan_Status',palette='ocean', ax=ax[1,0])
sns.scatterplot(data=loan_train,x='Loan_Amount_Term', y='LoanAmount', s=70, hue='Loan_Status',palette='ocean', ax=ax[1,1])

plt.show()

loan_train.corr()

"""Let's get a more high level view of the correlations between numeric variables"""

# Let's plot correlation overview of the variables.

fig, ax = plt.subplots(figsize=(9, 7))
correlations = loan_train.corr()

# plotting correlation heatmap
dataplot = sns.heatmap(correlations, cmap="YlGnBu", annot=True)
  
# displaying heatmap
plt.show()

"""Data Pre-processing for Model Building"""

# Let's take another preview of the data
loan_train.head()

#first identify all categorical columns & pass into a variable
objectlist_train = loan_train.select_dtypes(include = "object").columns


# Then Label Encoding for object to numeric conversion

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

for feature in objectlist_train:
    loan_train[feature] = le.fit_transform(loan_train[feature].astype(str))

print (loan_train.info())

# Now, repeat the same process to encode the test data

objectlist_test = loan_test.select_dtypes(include='object').columns

for feature in objectlist_test:
    loan_test[feature] = le.fit_transform(loan_test[feature].astype(str))

print (loan_test.info())

# Now let's rerun correlation, with other numeric variables now added

fig, ax = plt.subplots(figsize=(10, 8))
correlations_ML = loan_train.iloc[:,1:].corr() # filer out the Loan_ID column as it is not relevant
sns.heatmap(correlations_ML, cmap="YlGnBu", annot=True)
plt.show()

"""Machine Learning Model Development"""

x = loan_train.iloc[:,1:].drop('Loan_Status', axis=1) # drop loan_status column because that is what we are predicting
y = loan_train['Loan_Status']
train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.30, random_state=0)

"""Decision Tree Classifier Model

"""

df_model = DecisionTreeClassifier()
df_model.fit(train_x, train_y)
predict_y = df_model.predict(test_x)
print(classification_report(test_y, predict_y))



DT_SC= accuracy_score(predict_y, test_y)

print("Accuracy:", accuracy_score(predict_y, test_y))
print(f"{round(accuracy_score(predict_y, test_y)*100,2)}% Accurate")

"""Random Forest Classifier¶

"""

rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(train_x, train_y)
predict_y_2 = rf_model.predict(test_x)
print(classification_report(test_y, predict_y_2))
RF_SC=accuracy_score(predict_y_2,test_y)
print("Accuracy:", accuracy_score(predict_y_2, test_y))
print(f"{round(accuracy_score(predict_y_2, test_y)*100,2)}% Accurate")

"""XGBoost"""

XGB = XGBClassifier()
XGB.fit(train_x, train_y)

predict_y = XGB.predict(test_x)

#  prediction Summary by species
print(classification_report(test_y, predict_y))

# Accuracy score
XGB_SC = accuracy_score(predict_y,test_y)


print("Accuracy:", accuracy_score(predict_y, test_y))
print(f"{round(accuracy_score(predict_y, test_y)*100,2)}% Accurate")

"""Logistic Regression Model¶

"""

lr_model = LogisticRegression(solver='lbfgs', multi_class='auto')
lr_model.fit(train_x, train_y)
predict_y_3 = lr_model.predict(test_x)
print(classification_report(test_y, predict_y_3))

LR_SC= accuracy_score(predict_y_3, test_y)

print("Accuracy:", accuracy_score(predict_y_3, test_y))
print(f"{round(accuracy_score(predict_y_3, test_y)*100,2)}% Accurate")

score = [DT_SC,RF_SC,XGB_SC,LR_SC]
Models = pd.DataFrame({
    'n_neighbors': ["Decision Tree","Random Forest","XGBoost", "Logistic Regression"],
    'Score': score})
Models.sort_values(by='Score', ascending=False)

"""### Conclusion

There's a positive relationship between applicant income & loan amount.

There's also a positive relationship between credit history and loan status.
On average, men got more loans. Being married & educated (graduate) were also factors that resulted in loan approvals.

For our ML model, at 84% accuracy, the Logistic Regression model is the most suitable to make this prediction.

# END OF THE SCRIPTS
"""